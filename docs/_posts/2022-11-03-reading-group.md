---
layout: post
title: "Third Meeting of Reading Group"
location: "KEC 2057"
time: "1 PM - 2 PM"
---

The [Fall 2022 AIGSA reading group](https:///www.aigsa.club/agisf) is about AGI (Artificial General Intelligence) Safety Fundamentals. Join us for the second meeting, **even if you missed the first meeting**! Lunch will be provided.

This week's topic is **Threat models and types of solutions**. Here's an introduction from Richard Ngo, the developer of the curriculum:

> How might misaligned AGIs cause existential catastrophes, and how might we stop them? Two threat models are outlined in Christiano (2019) - the first focusing on outer misalignment, the second on inner misalignment. Muehlhauser and Salamon (2012) outline a core intuition for why we might be unable to prevent these risks: that progress in AI will at some point speed up dramatically. A third key intuition - that misaligned agents will try to deceive humans during training - is explored by Steinhardt (2022). Ngo (2022) evaluates the implications of these intuitions for our ability to control misaligned AGIs.

> How might we prevent these scenarios? Christiano (2020) gives a broad overview of the landscape of different contributions to making AIs aligned, with a particular focus on some of the techniques weâ€™ll be covering in later weeks.

To prepare, **please spend ~1 hour reading these short pieces:**

1.  [What failure looks like (Christiano, 2019)](https://www.alignmentforum.org/posts/HBxe6wdjxK239zajf/what-failure-looks-like) (10 mins)
2.  [Intelligence explosion: evidence and import (Muehlhauser and Salamon, 2012)](https://drive.google.com/file/d/1QxMuScnYvyq-XmxYeqBRHKz7cZoOosHr/view?usp=sharing) (only pages 10-15) (15 mins)
3.  [AGI safety from first principles (Ngo, 2020)](https://drive.google.com/file/d/1uK7NhdSKprQKZnRjU58X7NLA1auXlWHt/view) (only section 5: Control) (15 mins)
4.  [AI alignment landscape (Christiano, 2020)](https://forum.effectivealtruism.org/posts/63stBTw3WAW6k45dY/paul-christiano-current-work-in-ai-alignment) (35 mins)
