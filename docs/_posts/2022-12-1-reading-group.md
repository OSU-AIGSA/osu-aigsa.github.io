---
layout: post
title: "Final Meeting of Reading Group"
location: KEC 2087
time: "1 PM - 2 PM"
---

The [Fall 2022 AIGSA reading group](https:///www.aigsa.club/agisf) is about AGI (Artificial General Intelligence) Safety Fundamentals. Join us for the final meeting, **even if you missed earlier meetings**! Lunch will be provided.

This week's topics are **decomposing tasks** and **interpretability**. Here's an introduction from Richard Ngo, the developer of the curriculum:

> The most prominent research directions in technical AGI safety involve training AIs to do complex tasks by decomposing those tasks into simpler ones where humans can more easily evaluate AI behavior... Wu et al. (2021) uses recursive task decomposition in order to solve tasks that are too difficult to perform directly. This is one example of a more general class of techniques called *iterated amplification*...

> \[Another\] technique weâ€™ll discuss this week is *debate*, proposed by Irving et al. (2018). Unlike the other two techniques, debate focuses on evaluating claims made by language models, rather than supervising AI behavior over time...

> Our current methods of training capable neural networks give us very little insight into how or why they function. This week we cover the field of interpretability, which aims to change this by developing methods for understanding how neural networks think...

> Olah et al. (2020) explore how neural circuits build up representations of high-level features out of lower-level features...

To prepare, **please spend ~1.5 hours reading these pieces:**

1.  [Summarizing books with human feedback: blog post (Wu et al., 2021)](https://openai.com/blog/summarizing-books/) (5 mins)
2.  [AI safety via debate (Irving et al., 2018)](https://arxiv.org/abs/1805.00899) (ending after section 3) (35 mins)
	- Those without a background in complexity theory can skip section 2.2.
3.  [Zoom In: an introduction to circuits (Olah et al., 2020)](https://distill.pub/2020/circuits/zoom-in/) (35 mins)
